# HackathonONE (Oracle + Alura)

# üìä SentimentoAPI - An√°lise de Sentimento com IA e Microservi√ßos

> **Hackathon MVP**: Solu√ß√£o automatizada para classifica√ß√£o de feedbacks de clientes utilizando Processamento de Linguagem Natural (NLP).

## üí° Sobre o Projeto

Empresas recebem milhares de coment√°rios diariamente e n√£o conseguem ler todos manualmente. A **SentimentoAPI** resolve esse problema identificando automaticamente se um coment√°rio √© **Positivo** ou **Negativo**, permitindo:

  * Prioriza√ß√£o de atendimento a clientes insatisfeitos.
  * Monitoramento da imagem da marca em tempo real.
  * Gera√ß√£o de m√©tricas de qualidade (CSAT/NPS).

-----

## üöÄ Tecnologias

<div>
  <img src="https://img.shields.io/badge/Java-17-blue?style=for-the-badge&logo=java&logoColor=white">
  <img src="https://img.shields.io/badge/Spring_Boot-3.0.6-green?style=for-the-badge&logo=springboot&logoColor=white">
  <img src="https://img.shields.io/badge/Python-3.9-blue?style=for-the-badge&logo=python&logoColor=white">
  <img src="https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white">
  <img src="https://img.shields.io/badge/Scikit--learn-FF9800?style=for-the-badge&logo=scikit-learn&logoColor=white">
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white">
  <img src="https://img.shields.io/badge/Joblib-0095D9?style=for-the-badge&logo=python&logoColor=white">
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white">
</div>

<p>Este projeto utiliza as seguintes tecnologias:</p>
<ul>
  <li><strong>Java 17</strong>: Linguagem de programa√ß√£o utilizada para desenvolver o backend.</li>
  <li><strong>Spring Boot</strong>: Framework Java utilizado para desenvolver a API do sistema.</li>
  <li><strong>Python 3.9</strong>: Linguagem de programa√ß√£o usada no microservi√ßo de Data Science.</li>
  <li><strong>Flask</strong>: Framework Python para construir a API que hospeda o modelo de Machine Learning.</li>
  <li><strong>Scikit-learn</strong>: Biblioteca Python para machine learning, utilizada para treinar o modelo de sentimento.</li>
  <li><strong>Docker</strong>: Plataforma para automatizar a implanta√ß√£o de aplica√ß√µes em containers, facilitando o desenvolvimento e a execu√ß√£o do projeto em diferentes ambientes.</li>
  <li><strong>Joblib</strong>: Biblioteca Python para serializa√ß√£o do modelo treinado, permitindo seu carregamento eficiente no ambiente de produ√ß√£o.</li>
  <li><strong>TensorFlow</strong>: Embora o modelo atual utilize o Scikit-learn, o TensorFlow pode ser utilizado para treinamento mais avan√ßado, como redes neurais.</li>
</ul>

## üìä Estado do Projeto

![Progresso](https://img.shields.io/badge/Progresso-40%25-red?style=for-the-badge&labelColor=000000&color=FF0000&logo=github)

## üèóÔ∏è Arquitetura T√©cnica

### Explica√ß√£o do Diagrama Mermaid:

- **Usu√°rio Envia Texto**: O usu√°rio envia um texto para a API.
- **API Spring Boot**: A API recebe a requisi√ß√£o via **POST** e a envia para o microservi√ßo Python.
- **Microservi√ßo Python**: O microservi√ßo Python realiza a an√°lise de sentimento e retorna a previs√£o.
- **Resposta da API**: A previs√£o de sentimento √© retornada ao usu√°rio via API.
- **Op√ß√µes de A√ß√µes**: O usu√°rio pode optar por atualizar ou excluir a previs√£o de sentimento.

 ```mermaid
graph LR
    A[Usu√°rio Envia Texto] --> B{API Spring Boot}
    B --> C[Requisi√ß√£o POST para Python]
    C --> D[Microservi√ßo Python]
    D --> E[Retorno da Previs√£o de Sentimento]
    E --> F[Resposta da API com Previs√£o]
    F --> G[Usu√°rio Recebe Previs√£o]
    G --> H{Usu√°rio Op√ß√µes}
    H -->|Atualizar| I[PUT Atualiza Sentimento]
    H -->|Excluir| J[DELETE Exclui Sentimento]
```

### Data Science

  * **Python 3.9**
  * **Scikit-learn** (Modelo de Regress√£o Log√≠stica)
  * **Pandas** (Manipula√ß√£o de dados)
  * **TF-IDF Vectorizer** (Processamento de texto)
  * **Joblib** (Serializa√ß√£o do modelo)
  * **Flask** (Exposi√ß√£o do modelo como API)

### Infraestrutura

  * **Docker** & **Docker Compose**

-----

## üöÄ Como Executar

### Pr√©-requisito: Treinamento do Modelo

Antes de subir os containers, √© necess√°rio gerar o arquivo bin√°rio do modelo de IA.

1.  Acesse a pasta `ds-python`.
2.  Execute o script de treinamento (necess√°rio Python instalado localmente ou executar dentro de um container isolado):
    ```bash
    python treinar_modelo.py
    ```
    *Isso criar√° o arquivo `sentiment_model.joblib`.*

### Op√ß√£o 1: Rodando com Docker (Recomendado)

Na raiz do projeto (onde est√° o `docker-compose.yml`):

```bash
docker-compose up --build
```

Aguarde at√© ver as mensagens de log indicando que ambos os servi√ßos iniciaram.

  * **API Principal:** `http://localhost:8081`
  * **Servi√ßo de IA (Interno):** `http://localhost:5000`

### Op√ß√£o 2: Rodando Manualmente

**1. Subir o Servi√ßo de Data Science:**

```bash
cd ds-python
pip install -r requirements.txt
python app_python.py
# O servi√ßo rodar√° na porta 5000
```

**2. Subir o Back-End Java:**

```bash
cd backend-java
./mvnw spring-boot:run
# O servi√ßo rodar√° na porta 8080
```

-----

## üîå Documenta√ß√£o da API

### Endpoint: Classificar Sentimento

Analisa um texto e retorna a previs√£o do sentimento e a confian√ßa do modelo.

  * **URL:** `/sentiment`
  * **M√©todo:** `POST`
  * **Content-Type:** `application/json`

#### Exemplo de Requisi√ß√£o (Body)

```json
{
  "text": "O produto chegou r√°pido e a qualidade √© excelente!"
}
```

#### Exemplo de Resposta (Sucesso - 200 OK)

```json
{
  "previsao": "Positivo",
  "probabilidade": 0.92
}
```

#### Exemplo de Resposta (Negativo)

```json
{
  "text": "P√©ssimo atendimento, nunca mais compro."
}
```

**Sa√≠da:**

```json
{
  "previsao": "Negativo",
  "probabilidade": 0.88
}
```

#### Tratamento de Erros

  * **400 Bad Request:** Se o campo `text` estiver vazio ou nulo.
  * **500 Internal Server Error:** Caso o servi√ßo de IA esteja indispon√≠vel.

-----

## üß† Detalhes do Modelo de Data Science

Para este MVP, optamos por uma abordagem cl√°ssica e eficiente de Machine Learning Supervisionado:

1.  **Pr√©-processamento:** Limpeza b√°sica de texto.
2.  **Vetoriza√ß√£o (TF-IDF):** Transformamos os textos em n√∫meros baseados na frequ√™ncia e import√¢ncia das palavras no corpus.
3.  **Algoritmo (Regress√£o Log√≠stica):** Escolhido por ser r√°pido, interpret√°vel e apresentar excelente desempenho para classifica√ß√£o bin√°ria de textos curtos.
4.  **M√©tricas:** O modelo retorna n√£o apenas a classe (Pos/Neg), mas a probabilidade (`predict_proba`), permitindo definir *thresholds* de confian√ßa.

-----

## üîÆ Pr√≥ximos Passos (Roadmap)

  * [ ] Implementar banco de dados (H2/Postgres) para hist√≥rico de requisi√ß√µes.
  * [ ] Dashboard visual para acompanhar a m√©dia de sentimento.
  * [ ] Suporte a an√°lise de sentimento em m√∫ltiplos idiomas.
  * [ ] Autentica√ß√£o via API Key/JWT.

-----

*Desenvolvido pela Equipe para o Hackathon 2025.*

-----


# Descri√ß√£o Geral

Setor de neg√≥cio

Atendimento ao cliente / Marketing / Opera√ß√µes ‚Äî empresas que coletam opini√µes de clientes (avalia√ß√µes, coment√°rios em redes sociais, pesquisas de satisfa√ß√£o) e querem entender rapidamente se o sentimento √© positivo, neutro ou negativo.

Descri√ß√£o do projeto

Criar uma API simples que recebe textos (coment√°rios, avalia√ß√µes ou tweets), aplica um modelo de Data Science para classificar o sentimento (Atrasado / Pontual ‚Üí neste caso: Positivo / Neutro / Negativo ou bin√°rio Positivo / Negativo) e retorna o resultado em formato JSON, permitindo que aplica√ß√µes consumam essa predi√ß√£o automaticamente.

Necessidade do cliente (explica√ß√£o n√£o t√©cnica)

Um cliente (empresa) recebe muitos coment√°rios e n√£o consegue ler tudo manualmente. Ele quer:

saber rapidamente se os clientes est√£o reclamando ou elogiando;

priorizar respostas a coment√°rios negativos;

medir a satisfa√ß√£o ao longo do tempo.

Esse projeto oferece uma solu√ß√£o autom√°tica para classificar mensagens e gerar informa√ß√µes acion√°veis.

Valida√ß√£o de mercado

Analisar sentimento √© √∫til para:

acelerar atendimento ao cliente (identificar urg√™ncias);

monitorar campanhas de marketing;

comparar a imagem da marca ao longo do tempo.

Mesmo uma solu√ß√£o simples (modelo b√°sico) tem valor: empresas pequenas e m√©dias usam ferramentas similares para entender feedbacks sem equipe dedicada.

Expectativa para este hackathon

P√∫blico: alunos sem experi√™ncia profissional na √°rea de tecnologia, que estudaram Back-end (Java, Spring, REST, persist√™ncia) e Data Science (Python, Pandas, scikit-learn, notebooks).

Objetivo: entregar um MVP funcional que demonstre integra√ß√£o entre DS e Back-end: um notebook com o modelo + uma API que carrega esse modelo e responde a requisi√ß√µes.

Escopo recomendado: classifica√ß√£o bin√°ria (Positivo / Negativo) ou trin√°ria (Positivo / Neutro / Negativo) com um modelo simples ‚Äî por exemplo, usar TF-IDF (uma t√©cnica que transforma o texto em n√∫meros, mostrando quais palavras s√£o mais importantes) junto com Regress√£o Log√≠stica (um modelo de aprendizado de m√°quina que aprende a diferenciar sentimentos).

Entreg√°veis desejados

Notebook (Jupyter/Colab) do time de Data Science contendo:

Explora√ß√£o e limpeza dos dados (EDA);

Transforma√ß√£o dos textos em n√∫meros com TF-IDF;

Treinamento de modelo supervisionado (ex.: Logistic Regression, Naive Bayes);

M√©tricas de desempenho (Acur√°cia, Precis√£o, Recall, F1-score);

Serializa√ß√£o do modelo (joblib/pickle).

Aplica√ß√£o Back-End (preferencialmente Spring Boot em Java):

API que consome o modelo (diretamente ou chamando o microservi√ßo DS) e exp√µe endpoint /sentiment;

Endpoint que recebe informa√ß√µes e retorna a previs√£o do modelo;

Logs e tratamento de erros.

Documenta√ß√£o m√≠nima (README):

Como executar o modelo e a API;

Exemplos de requisi√ß√£o e resposta (JSON);

Depend√™ncias e vers√µes das ferramentas.

Demonstra√ß√£o funcional (Apresenta√ß√£o curta):

Mostrar a API em a√ß√£o (via Postman, cURL ou interface simples);

Explicar como o modelo chega √† previs√£o.

Funcionalidades exigidas (MVP)

O servi√ßo deve expor um endpoint que retorna a classifica√ß√£o do sentimento e a probabilidade associada a essa classifica√ß√£o. Exemplo: POST /sentiment ‚Äî aceita JSON com campo text e retorna: { "previsao": "Positivo", "probabilidade": 0.87 }

Modelo treinado e carreg√°vel: o back-end deve conseguir usar o modelo (carregando arquivo) ou fazer uma requisi√ß√£o a um microservi√ßo DS que implemente a predi√ß√£o.

Valida√ß√£o de input: checar se text existe e tem comprimento m√≠nimo; retornar erro amig√°vel em caso contr√°rio.

Resposta clara: label (+ probabilidade em 0‚Äì1) e mensagem de erro quando aplic√°vel.

Exemplos de uso: Postman/cURL com 3 exemplos reais (positivo, neutro, negativo).

README explicando como rodar (passos simples) e como testar o endpoint.

Funcionalidades opcionais

Endpoint GET /stats com estat√≠sticas simples (percentual de positivos/negativos nos √∫ltimos X coment√°rios).

Persist√™ncia: salvar requisi√ß√µes e previs√µes em banco (H2 ou Postgres) para an√°lises posteriores.

Explicabilidade b√°sica: retornar as palavras mais influentes na predi√ß√£o (ex.: "top features": ["√≥timo", "atendimento"]).

Interface simples (Streamlit / p√°gina web) para testar texto livremente.

Batch processing: endpoint para enviar v√°rios textos em CSV e receber previs√µes em lote.

Vers√£o multilingue (Portugu√™s + Espanhol) ou op√ß√£o para trocar o threshold de probabilidade.

Containeriza√ß√£o com Docker e docker-compose para subir DS + BE juntos.

Testes automatizados: alguns testes unit√°rios e um teste de integra√ß√£o simples.

Orienta√ß√µes t√©cnicas para alunos

Recomendamos cuidado quando da utiliza√ß√£o limitada das inst√¢ncias fornecidas pelos servi√ßos always free da OCI, para n√£o acarretar em gastos adicionais.

Time de Data Science

Cada equipe deve escolher ou montar seu pr√≥prio conjunto de dados de coment√°rios, avalia√ß√µes ou postagens que possam ser usados para an√°lise de sentimento (ex.: reviews p√∫blicos, tweets, avalia√ß√µes de produtos etc.).

use Python, Pandas para ler/limpar dados;

crie um modelo simples (TF-IDF + LogisticRegression do scikit-learn);

salve o pipeline e o modelo com joblib.dump.

Coloque tudo em um notebook bem comentado.

Time de Back-End

crie uma API REST (em Java com Spring Boot).

Implementar um endpoint (ex: /sentiment ) que recebe a avalia√ß√£o e retorna o sentimento

Integrar o modelo de Data Science:

via microservi√ßo Python (FastAPI/Flask), ou

carregando o modelo exportado (ONNX, para times Java avan√ßados).

Validar entradas e retornar respostas JSON consistentes.

Contrato de integra√ß√£o (definido entre DS e BE)

Recomendamos definir desde o in√≠cio o formato JSON de entrada e sa√≠da. Segue um exemplo:

{"text": "‚Ä¶"} ‚Üí

{

"previsao":"Positivo",

Esse √© um projeto cl√°ssico e excelente para um Hackathon, pois demonstra perfeitamente a integra√ß√£o entre sistemas.

Como Java n√£o consegue ler nativamente arquivos serializados do Python (`.joblib` ou `.pkl`) de forma simples, a arquitetura padr√£o da ind√∫stria para esse cen√°rio √© a de **Microservi√ßos**.

Aqui est√° o roteiro completo e o c√≥digo para o seu **MVP**, dividido em duas partes: o **Servi√ßo de Data Science (Python)** e a **API Principal (Java Spring Boot)**.

[Image of microservices architecture pattern]

-----

### 1\. Time de Data Science (Python)

O objetivo aqui √© treinar o modelo e exp√¥-lo via uma API leve (Flask ou FastAPI) para que o Java possa consult√°-lo.

#### A. O Notebook de Treinamento (`treinar_modelo.py`)

Este script simula o notebook. Ele cria dados fict√≠cios, treina o modelo usando **TF-IDF** e **Regress√£o Log√≠stica**, e salva o arquivo.

**Conceito T√©cnico:**
O TF-IDF ($Term Frequency - Inverse Document Frequency$) transforma texto em n√∫meros. A f√≥rmula b√°sica para o peso de um termo √©:
$$w_{i,j} = tf_{i,j} \times \log(\frac{N}{df_i})$$
Onde a Regress√£o Log√≠stica usa esses pesos para tra√ßar uma linha divis√≥ria entre "Positivo" e "Negativo".

```python
# treinar_modelo.py
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib

# 1. Dataset Fict√≠cio (Em um caso real, carregue um CSV)
data = {
    'texto': [
        "Adorei o produto, muito bom", "Excelente atendimento", "Entrega r√°pida e perfeita",
        "Gostei bastante, recomendo", "Maravilhoso", "Muito satisfat√≥rio",
        "O produto chegou quebrado", "P√©ssimo servi√ßo", "N√£o recomendo a ningu√©m",
        "Demorou muito e veio errado", "Horr√≠vel", "Estou muito insatisfeito",
        "O atendimento foi normal", "Nada de especial", "Chegou no prazo mas a caixa amassou"
    ],
    'sentimento': [
        "Positivo", "Positivo", "Positivo", "Positivo", "Positivo", "Positivo",
        "Negativo", "Negativo", "Negativo", "Negativo", "Negativo", "Negativo",
        "Neutro", "Neutro", "Neutro"
    ]
}

df = pd.DataFrame(data)

# 2. Separa√ß√£o de dados
X = df['texto']
y = df['sentimento']

# 3. Cria√ß√£o do Pipeline (TF-IDF + Regress√£o Log√≠stica)
model = make_pipeline(TfidfVectorizer(), LogisticRegression())

# 4. Treinamento
model.fit(X, y)

# 5. Teste r√°pido
print("Acur√°cia no treino:", model.score(X, y))

# 6. Serializa√ß√£o (Salvar o modelo)
joblib.dump(model, 'sentiment_model.joblib')
print("Modelo salvo como 'sentiment_model.joblib'")
```

#### B. A API do Modelo (`app_python.py`)

Esta √© a API que o Spring Boot vai chamar. Ela carrega o arquivo `.joblib` e responde a requisi√ß√µes. Vamos usar **Flask** por ser simples.

```python
# app_python.py
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)

# Carrega o modelo ao iniciar a API
try:
    model = joblib.load('sentiment_model.joblib')
    print("Modelo carregado com sucesso!")
except:
    print("Erro: Execute o script de treinamento primeiro.")

@app.route('/predict', methods=['POST'])
def predict():
    dados = request.get_json()
    texto = dados.get('text')

    if not texto:
        return jsonify({"erro": "Texto n√£o fornecido"}), 400

    # Predi√ß√£o
    prediction = model.predict([texto])[0]
    # Probabilidade (pega a maior probabilidade entre as classes)
    proba = max(model.predict_proba([texto])[0])

    return jsonify({
        "previsao": prediction,
        "probabilidade": float(round(proba, 2))
    })

if __name__ == '__main__':
    # Roda na porta 5000
    app.run(port=5000, debug=True)
```

-----

### 2\. Time de Back-End (Java Spring Boot)

O Spring Boot ser√° a "porta de entrada". Ele recebe a requisi√ß√£o do cliente, valida, chama o Python, e devolve a resposta.

**Estrutura do Projeto:**

  * `SentimentController.java`: Recebe o POST.
  * `SentimentService.java`: L√≥gica de neg√≥cio e chamada HTTP ao Python.
  * `SentimentRequest.java` e `SentimentResponse.java`: DTOs (Data Transfer Objects).

#### Depend√™ncias (`pom.xml`)

Adicione apenas `spring-boot-starter-web`.

#### A. Os DTOs (Classes de dados)

```java
// SentimentRequest.java
public class SentimentRequest {
    private String text;
    // Getters e Setters
    public String getText() { return text; }
    public void setText(String text) { this.text = text; }
}

// SentimentResponse.java
public class SentimentResponse {
    private String previsao;
    private Double probabilidade;
    // Getters e Setters, Construtores
}
```

#### B. O Service (L√≥gica e Integra√ß√£o)

Aqui usamos `RestTemplate` para conectar o Java ao Python.

```java
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;
import org.springframework.http.ResponseEntity;

@Service
public class SentimentService {

    // URL do servi√ßo Python
    private final String ML_SERVICE_URL = "http://localhost:5000/predict";

    public SentimentResponse analisarSentimento(String texto) {
        // 1. Valida√ß√£o de Regra de Neg√≥cio
        if (texto == null || texto.trim().isEmpty()) {
            throw new IllegalArgumentException("O texto n√£o pode estar vazio.");
        }

        // 2. Preparar requisi√ß√£o para o Python
        RestTemplate restTemplate = new RestTemplate();
        SentimentRequest request = new SentimentRequest();
        request.setText(texto);

        // 3. Chamar o Python e pegar resposta
        try {
            SentimentResponse response = restTemplate.postForObject(ML_SERVICE_URL, request, SentimentResponse.class);
            return response;
        } catch (Exception e) {
            // Fallback caso o Python esteja fora do ar
            throw new RuntimeException("Erro ao conectar com o servi√ßo de IA: " + e.getMessage());
        }
    }
}
```

#### C. O Controller (O Endpoint)

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/sentiment")
public class SentimentController {

    @Autowired
    private SentimentService service;

    @PostMapping
    public ResponseEntity<?> classificar(@RequestBody SentimentRequest request) {
        try {
            SentimentResponse resultado = service.analisarSentimento(request.getText());
            return ResponseEntity.ok(resultado);
        } catch (IllegalArgumentException e) {
            return ResponseEntity.badRequest().body("Erro de valida√ß√£o: " + e.getMessage());
        } catch (Exception e) {
            return ResponseEntity.internalServerError().body("Erro interno: " + e.getMessage());
        }
    }
}
```

-----

### 3\. Como Rodar e Testar (O Passo a Passo)

Para apresentar isso no Hackathon, siga esta ordem exata:

1.  **Prepare o Ambiente Python:**

    ```bash
    pip install pandas scikit-learn flask
    python treinar_modelo.py  # Isso vai criar o arquivo .joblib
    python app_python.py      # Isso sobe o servidor na porta 5000
    ```

2.  **Suba o Spring Boot:**

      * Execute a aplica√ß√£o Java (geralmente porta 8080).

3.  **Teste (Via Postman ou cURL):**

**Requisi√ß√£o (POST para localhost:8080/sentiment):**

```json
{
  "text": "O atendimento foi p√©ssimo, odiei tudo."
}
```

**Resposta Esperada:**

```json
{
  "previsao": "Negativo",
  "probabilidade": 0.85
}
```

### Dicas para a Apresenta√ß√£o (O "Pulo do Gato")

1.  **Explicabilidade:** Se perguntarem por que escolheu essa arquitetura, diga: *"O desacoplamento permite que o time de Data Science evolua o modelo (mude de Regress√£o Log√≠stica para Rede Neural, por exemplo) sem que o time de Back-End precise alterar uma linha de c√≥digo Java, apenas mantendo o contrato da API."*
2.  **Tratamento de Erros:** Note que no Java eu coloquei um `try-catch`. Se o Python cair, o Java n√£o "explode", ele avisa que o servi√ßo de IA est√° indispon√≠vel. Isso conta pontos.
"probabilidade":0.9

}
